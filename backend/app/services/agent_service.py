from langchain.agents import create_agent
from langchain_core.tools import Tool
from langchain_core.messages import HumanMessage, AIMessage
from typing import List, Dict, Optional, AsyncIterator, Any
import asyncio
from datetime import datetime
from app.core.config import settings
from app.services.knowledge_service import knowledge_service
from app.services.llm_factory import llm_factory
from app.services.agent import RolePresetRetriever
from app.services.memory import MemoryManager
from app.services.streaming import StreamCallbackHandler
from app.services.tools import (
    create_web_search_tool,
    web_scraper_tool,
    pdf_parser_tool,
    knowledge_retrieval_tool
)
from app.api.schemas import AgentConfig
from loguru import logger


class AgentService:
    """AgentæœåŠ¡ - å¤„ç†é—®ç­”å’Œæ¨ç†è§„åˆ’"""
    
    def __init__(self):
        # åˆå§‹åŒ–é»˜è®¤LLM
        self.llm = llm_factory.create_llm()
    
    def _get_llm(self, provider: Optional[str] = None, model: Optional[str] = None, streaming: bool = False):
        """è·å–LLMå®ä¾‹"""
        if provider or model:
            # ç›´æ¥ä¼ é€’streamingå‚æ•°ç»™factory
            llm = llm_factory.create_llm(provider=provider, model_name=model, streaming=streaming)
            return llm
        # å¯¹äºé»˜è®¤LLMï¼Œå¦‚æœéœ€è¦streamingï¼Œéœ€è¦é‡æ–°åˆ›å»º
        if streaming:
            return llm_factory.create_llm(streaming=True)
        return self.llm
        
    def _create_tools(self, search_provider: Optional[str] = None) -> List[Tool]:
        """åˆ›å»ºAgentå¯ç”¨çš„å·¥å…·
        
        Args:
            search_provider: æœç´¢æä¾›å•†ï¼Œå¯é€‰å€¼: 'tavily', 'baidu', None(é»˜è®¤ä½¿ç”¨tavily)
        """
        
        def calculator_tool(expression: str) -> str:
            """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
            try:
                # å®‰å…¨çš„æ•°å­¦è®¡ç®—
                import math
                allowed_names = {
                    k: v for k, v in math.__dict__.items() 
                    if not k.startswith("__")
                }
                result = eval(expression, {"__builtins__": {}}, allowed_names)
                return f"è®¡ç®—ç»“æœ: {result}"
            except Exception as e:
                return f"è®¡ç®—é”™è¯¯: {str(e)}"
        
        tools = [
            Tool(
                name="calculator",
                func=calculator_tool,
                description="æ‰§è¡Œæ•°å­¦è®¡ç®—ã€‚è¾“å…¥åº”è¯¥æ˜¯ä¸€ä¸ªæ•°å­¦è¡¨è¾¾å¼ï¼Œä¾‹å¦‚: '2+2' æˆ– '10*5' æˆ– 'sqrt(16)'ã€‚"
            )
        ]
        
        # æ·»åŠ çŸ¥è¯†åº“æ£€ç´¢å·¥å…·
        if knowledge_retrieval_tool:
            tools.append(knowledge_retrieval_tool)
        
        # åˆ›å»ºç»Ÿä¸€çš„è”ç½‘æœç´¢å·¥å…·ï¼ˆæ ¹æ®search_provideré€‰æ‹©Tavilyæˆ–ç™¾åº¦ï¼‰
        web_search = create_web_search_tool(search_provider=search_provider)
        if web_search:
            tools.append(web_search)
            logger.info(f"Added web search tool (provider: {search_provider or 'tavily'})")
        else:
            logger.warning("Web search tool not available")
        
        # æ·»åŠ ç½‘é¡µæŠ“å–å·¥å…·
        if web_scraper_tool:
            tools.append(web_scraper_tool)
        
        # æ·»åŠ PDFè§£æå·¥å…·
        if pdf_parser_tool:
            tools.append(pdf_parser_tool)
        
        logger.info(f"Created {len(tools)} tools for agent (search provider: {search_provider or 'tavily'})")
        return tools
    
    def create_agent(
        self, 
        config: Optional[AgentConfig] = None,
        **kwargs  # ä¿æŒå‘åå…¼å®¹ï¼Œæ”¯æŒæ—§çš„æ–¹å¼ä¼ å‚
    ) -> Any:
        """åˆ›å»ºAgent
        
        Args:
            config: Agenté…ç½®å¯¹è±¡ï¼ˆæ¨èä½¿ç”¨ï¼‰
            **kwargs: å‘åå…¼å®¹çš„æ—§å‚æ•°æ–¹å¼ï¼ˆå¦‚æœæä¾›äº†configï¼Œkwargså°†è¢«å¿½ç•¥ï¼‰
                - memory: å¯¹è¯å†…å­˜
                - provider: LLMæä¾›å•†
                - model: æ¨¡å‹åç§°
                - collection: çŸ¥è¯†åº“é›†åˆåç§°
                - message: ç”¨æˆ·æ¶ˆæ¯ï¼ˆç”¨äºæ£€ç´¢è§’è‰²é¢„è®¾ï¼‰
                - search_provider: æœç´¢æä¾›å•†ï¼Œå¯é€‰å€¼: 'tavily', 'baidu', None(é»˜è®¤ä½¿ç”¨tavily)
                - role_preset_id: æŒ‡å®šçš„è§’è‰²é¢„è®¾ID
                - db_session: æ•°æ®åº“ä¼šè¯
                - llm_instance: å¯é€‰çš„LLMå®ä¾‹ï¼ˆå¦‚æœæä¾›åˆ™ç›´æ¥ä½¿ç”¨ï¼‰
        
        Returns:
            Agent å®ä¾‹ï¼ˆå¯ç›´æ¥è°ƒç”¨ invoke/ainvokeï¼‰
        """
        # å¦‚æœæä¾›äº†kwargsä½†æ²¡æœ‰configï¼Œä»kwargsåˆ›å»ºconfigï¼ˆå‘åå…¼å®¹ï¼‰
        if config is None and kwargs:
            config = AgentConfig(**kwargs)
        elif config is None:
            config = AgentConfig()
        
        # è·å–LLMå®ä¾‹ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if config.llm_instance:
            llm = config.llm_instance
        else:
            llm = self._get_llm(config.provider, config.model, streaming=False)
        
        # åˆ›å»ºå·¥å…·åˆ—è¡¨ï¼ˆæ ¹æ®search_provideré€‰æ‹©æœç´¢å·¥å…·ï¼‰
        tools = self._create_tools(search_provider=config.search_provider)
        
        # è·å–è§’è‰²é¢„è®¾æç¤ºè¯
        role_prompts = RolePresetRetriever.retrieve_prompts(
            role_preset_id=config.role_preset_id,
            collection=config.collection,
            message=config.message,
            db_session=config.db_session,
            top_k=3
        )
        
        # è·å–å†å²å¯¹è¯ä¸Šä¸‹æ–‡
        history_context = MemoryManager.get_history_context(config.memory, max_messages=20) if config.memory else ""
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½AIåŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©å›ç­”é—®é¢˜ã€‚{role_prompts}{history_context}

ğŸ”§ ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·:
â€¢ knowledge_base_search - ä»å†…éƒ¨çŸ¥è¯†åº“æ£€ç´¢ä¿¡æ¯ï¼ˆæç¤ºè¯æ¨¡æ¿ã€æ–‡æ¡£ã€å†å²è®°å½•ï¼‰
â€¢ web_search - è”ç½‘æœç´¢æœ€æ–°ä¿¡æ¯ã€æ–°é—»ã€å®æ—¶æ•°æ®ã€å¤©æ°”ï¼ˆå¯åœ¨é¡µé¢åˆ‡æ¢Tavilyæˆ–ç™¾åº¦ï¼‰
â€¢ web_content_fetcher - è·å–æŒ‡å®šURLçš„ç½‘é¡µå†…å®¹
â€¢ pdf_parser - è§£æPDFæ–‡ä»¶å†…å®¹
â€¢ calculator - æ‰§è¡Œæ•°å­¦è®¡ç®—

ğŸ’¡ é‡è¦æç¤º:
1. å½“ç”¨æˆ·è¯¢é—®å¤©æ°”ã€æ–°é—»ã€è‚¡ä»·ç­‰å®æ—¶ä¿¡æ¯æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ web_search å·¥å…·ï¼
2. è¯·ç”¨ä¸­æ–‡å›ç­”æ‰€æœ‰é—®é¢˜ï¼Œç¡®ä¿ç­”æ¡ˆä¸“ä¸šã€è¯¦ç»†ã€æœ‰æ¡ç†ã€‚
3. è¯·å‚è€ƒå¯¹è¯å†å²ï¼Œç†è§£ç”¨æˆ·çš„æ„å›¾å’Œä¸Šä¸‹æ–‡ï¼Œä¿æŒå¯¹è¯çš„è¿è´¯æ€§ã€‚"""
        
        # è·å– LangGraph çš„å­˜å‚¨å®ä¾‹
        checkpointer = MemoryManager.get_short_term_saver()  # çŸ­æœŸè®°å¿†
        store = MemoryManager.get_long_term_store()  # é•¿æœŸè®°å¿†
        
        # ä½¿ç”¨ç»Ÿä¸€çš„ create_agent APIï¼Œé›†æˆ LangGraph çš„å­˜å‚¨æœºåˆ¶
        logger.info(f"Creating agent with {len(tools)} tools (provider: {config.provider or settings.LLM_PROVIDER})")
        agent = create_agent(
            model=llm,
            tools=tools,
            system_prompt=system_prompt,
            checkpointer=checkpointer,  # ä½¿ç”¨ InMemorySaver ç®¡ç†çŸ­æœŸè®°å¿†
            store=store  # ä½¿ç”¨ InMemoryStore ç®¡ç†é•¿æœŸè®°å¿†
        )
        
        return agent
    
    async def create_async_agent(
        self,
        config: Optional[AgentConfig] = None,
        **kwargs  # ä¿æŒå‘åå…¼å®¹ï¼Œæ”¯æŒæ—§çš„æ–¹å¼ä¼ å‚
    ) -> Any:
        """åˆ›å»ºå¼‚æ­¥Agentï¼ˆç”¨äº ainvoke è°ƒç”¨ï¼‰
        
        Args:
            config: Agenté…ç½®å¯¹è±¡ï¼ˆæ¨èä½¿ç”¨ï¼‰
            **kwargs: å‘åå…¼å®¹çš„æ—§å‚æ•°æ–¹å¼ï¼ˆå¦‚æœæä¾›äº†configï¼Œkwargså°†è¢«å¿½ç•¥ï¼‰
                - provider: LLMæä¾›å•†
                - model: æ¨¡å‹åç§°
                - collection: çŸ¥è¯†åº“é›†åˆåç§°
                - message: ç”¨æˆ·æ¶ˆæ¯ï¼ˆç”¨äºæ£€ç´¢è§’è‰²é¢„è®¾ï¼‰
                - search_provider: æœç´¢æä¾›å•†ï¼Œå¯é€‰å€¼: 'tavily', 'baidu', None(é»˜è®¤ä½¿ç”¨tavily)
                - role_preset_id: æŒ‡å®šçš„è§’è‰²é¢„è®¾ID
                - db_session: æ•°æ®åº“ä¼šè¯
                - llm_instance: å¯é€‰çš„LLMå®ä¾‹ï¼ˆå¦‚æœæä¾›åˆ™ç›´æ¥ä½¿ç”¨ï¼‰
        
        Returns:
            Agent å®ä¾‹ï¼ˆå¯ç›´æ¥è°ƒç”¨ ainvokeï¼‰
        """
        # å¦‚æœæä¾›äº†kwargsä½†æ²¡æœ‰configï¼Œä»kwargsåˆ›å»ºconfigï¼ˆå‘åå…¼å®¹ï¼‰
        if config is None and kwargs:
            config = AgentConfig(**kwargs)
        elif config is None:
            config = AgentConfig()
        
        # è·å–LLMå®ä¾‹ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if config.llm_instance:
            llm = config.llm_instance
        else:
            llm = self._get_llm(config.provider, config.model, streaming=False)
        
        # åˆ›å»ºå·¥å…·åˆ—è¡¨ï¼ˆæ ¹æ®search_provideré€‰æ‹©æœç´¢å·¥å…·ï¼‰
        tools = self._create_tools(search_provider=config.search_provider)
        
        # è·å–è§’è‰²é¢„è®¾æç¤ºè¯
        role_prompts = RolePresetRetriever.retrieve_prompts(
            role_preset_id=config.role_preset_id,
            collection=config.collection,
            message=config.message,
            db_session=config.db_session,
            top_k=3
        )
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½AIåŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©å›ç­”é—®é¢˜ã€‚{role_prompts}

ğŸ”§ ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·:
â€¢ knowledge_base_search - ä»å†…éƒ¨çŸ¥è¯†åº“æ£€ç´¢ä¿¡æ¯ï¼ˆæç¤ºè¯æ¨¡æ¿ã€æ–‡æ¡£ã€å†å²è®°å½•ï¼‰
â€¢ web_search - è”ç½‘æœç´¢æœ€æ–°ä¿¡æ¯ã€æ–°é—»ã€å®æ—¶æ•°æ®ã€å¤©æ°”ï¼ˆå¯åœ¨é¡µé¢åˆ‡æ¢Tavilyæˆ–ç™¾åº¦ï¼‰
â€¢ web_content_fetcher - è·å–æŒ‡å®šURLçš„ç½‘é¡µå†…å®¹
â€¢ pdf_parser - è§£æPDFæ–‡ä»¶å†…å®¹
â€¢ calculator - æ‰§è¡Œæ•°å­¦è®¡ç®—

ğŸ’¡ é‡è¦æç¤º:
1. å½“ç”¨æˆ·è¯¢é—®å¤©æ°”ã€æ–°é—»ã€è‚¡ä»·ç­‰å®æ—¶ä¿¡æ¯æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ web_search å·¥å…·ï¼
2. è¯·ç”¨ä¸­æ–‡å›ç­”æ‰€æœ‰é—®é¢˜ï¼Œç¡®ä¿ç­”æ¡ˆä¸“ä¸šã€è¯¦ç»†ã€æœ‰æ¡ç†ã€‚
3. è¯·å‚è€ƒå¯¹è¯å†å²ï¼Œç†è§£ç”¨æˆ·çš„æ„å›¾å’Œä¸Šä¸‹æ–‡ï¼Œä¿æŒå¯¹è¯çš„è¿è´¯æ€§ã€‚"""
        
        # è·å– LangGraph çš„å¼‚æ­¥å­˜å‚¨å®ä¾‹
        checkpointer = await MemoryManager.get_short_term_saver()  # çŸ­æœŸè®°å¿†
        store = MemoryManager.get_long_term_store()  # é•¿æœŸè®°å¿†
        
        # ä½¿ç”¨ç»Ÿä¸€çš„ create_agent APIï¼Œé›†æˆ LangGraph çš„å­˜å‚¨æœºåˆ¶
        logger.info(f"Creating async agent with {len(tools)} tools (provider: {config.provider or settings.LLM_PROVIDER})")
        agent = create_agent(
            model=llm,
            tools=tools,
            system_prompt=system_prompt,
            checkpointer=checkpointer,  # ä½¿ç”¨ AsyncPostgresSaver ç®¡ç†çŸ­æœŸè®°å¿†
            store=store  # ä½¿ç”¨ InMemoryStore ç®¡ç†é•¿æœŸè®°å¿†
        )
        
        return agent
    
    def _format_intermediate_steps(self, intermediate_steps: List) -> List[Dict]:
        """æ ¼å¼åŒ–ä¸­é—´æ­¥éª¤ï¼Œä½¿å…¶æ›´æ˜“è¯»"""
        formatted_steps = []
        
        for step in intermediate_steps:
            try:
                # intermediate_steps æ ¼å¼: [(AgentAction, result), ...]
                if isinstance(step, tuple) and len(step) == 2:
                    action, result = step
                    
                    # æå–å·¥å…·åç§°å’Œè¾“å…¥
                    tool_name = getattr(action, 'tool', 'unknown')
                    tool_input = getattr(action, 'tool_input', '')
                    log = getattr(action, 'log', '')
                    
                    # æ ¼å¼åŒ–ç»“æœï¼ˆé™åˆ¶é•¿åº¦ï¼‰
                    result_str = str(result)
                    if len(result_str) > 500:
                        result_str = result_str[:500] + "...(å†…å®¹è¿‡é•¿å·²æˆªæ–­)"
                    
                    formatted_steps.append({
                        "tool": tool_name,
                        "input": tool_input,
                        "output": result_str,
                        "log": log
                    })
            except Exception as e:
                logger.warning(f"Error formatting step: {e}")
                continue
        
        return formatted_steps
    
    
    async def chat_stream(
        self,
        message: str,
        config: Optional[AgentConfig] = None,
        **kwargs  # ä¿æŒå‘åå…¼å®¹ï¼Œæ”¯æŒæ—§çš„æ–¹å¼ä¼ å‚
    ) -> AsyncIterator[Dict]:
        """æµå¼å¤„ç†å¯¹è¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            config: Agenté…ç½®å¯¹è±¡ï¼ˆæ¨èä½¿ç”¨ï¼‰
            **kwargs: å‘åå…¼å®¹çš„æ—§å‚æ•°æ–¹å¼ï¼ˆå¦‚æœæä¾›äº†configï¼Œkwargså°†è¢«å¿½ç•¥ï¼‰
                - history: å†å²å¯¹è¯è®°å½•
                - collection: çŸ¥è¯†åº“é›†åˆåç§°
                - provider: LLMæä¾›å•†
                - model: æ¨¡å‹åç§°
                - search_provider: æœç´¢æä¾›å•†
                - role_preset_id: æŒ‡å®šçš„è§’è‰²é¢„è®¾ID
                - deep_reasoning: æ·±åº¦æ¨ç†æ¨¡å¼
                - db_session: æ•°æ®åº“ä¼šè¯
                - thread_id: çº¿ç¨‹IDï¼Œç”¨äºæ ‡è¯†ä¸åŒçš„ä¼šè¯ï¼ˆç”¨äº LangGraph checkpointï¼‰
        """
        # å¦‚æœæä¾›äº†kwargsä½†æ²¡æœ‰configï¼Œä»kwargsåˆ›å»ºconfigï¼ˆå‘åå…¼å®¹ï¼‰
        if config is None and kwargs:
            config = AgentConfig(**kwargs)
        elif config is None:
            config = AgentConfig()
        
        try:
            # åˆ›å»ºmemoryå¹¶åŠ è½½å†å²å¯¹è¯
            #memory = MemoryManager.create_memory(history=config.history, max_history_length=20, thread_id=config.thread_id)
            
            # åˆ›å»ºæµå¼å›è°ƒå¤„ç†å™¨
            stream_handler = StreamCallbackHandler()
            
            # è·å–LLMå®ä¾‹å¹¶å¯ç”¨æµå¼è¾“å‡º
            llm = self._get_llm(config.provider, config.model, streaming=True)
            
            # è®¾ç½®å›è°ƒå¤„ç†å™¨åˆ°LLMä¸Šï¼ˆå¿…é¡»åœ¨åˆ›å»ºagentä¹‹å‰ï¼‰
            if hasattr(llm, 'callbacks'):
                if llm.callbacks:
                    llm.callbacks.append(stream_handler)
                else:
                    llm.callbacks = [stream_handler]
            logger.info(f"LLM callbacks set: {hasattr(llm, 'callbacks')}")
            
            # åˆ›å»ºå¼‚æ­¥agentï¼ˆä½¿ç”¨å·²è®¾ç½®å›è°ƒçš„LLMï¼‰
            agent_config = AgentConfig(
                provider=config.provider,
                model=config.model,
                collection=config.collection,
                message=message,
                search_provider=config.search_provider,
                role_preset_id=config.role_preset_id,
                db_session=config.db_session,
                llm_instance=llm
            )
            agent = await self.create_async_agent(config=agent_config)
            
            # è®¾ç½®å›è°ƒåˆ°agentä¸Š
            if hasattr(agent, 'callbacks'):
                if agent.callbacks:
                    agent.callbacks.append(stream_handler)
                else:
                    agent.callbacks = [stream_handler]
            logger.info(f"Agent callbacks set: {hasattr(agent, 'callbacks')}")
            
            # ä½¿ç”¨ainvokeæ‰§è¡Œï¼Œé€šè¿‡å›è°ƒå¤„ç†å™¨æ•è·æµå¼è¾“å‡º
            try:
                agent_done = False
                agent_error = None
                final_result = None
                
                async def run_agent():
                    nonlocal agent_done, agent_error, final_result
                    try:
                        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                        messages = []
                        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
                        messages.append(HumanMessage(content=message))
                        
                        # æ„å»ºè°ƒç”¨é…ç½®ï¼ˆå¦‚æœæä¾›äº† thread_idï¼Œä½¿ç”¨ LangGraph checkpointï¼‰
                        invoke_config = {}
                        if config.thread_id:
                            invoke_config = {"configurable": {"thread_id": config.thread_id}}
                        
                        # ç›´æ¥ä½¿ç”¨ainvokeï¼Œå›è°ƒå¤„ç†å™¨ä¼šæ•è·æµå¼token
                        if invoke_config:
                            result = await agent.ainvoke({"messages": messages}, config=invoke_config)
                        else:
                            result = await agent.ainvoke({"messages": messages})
                        final_result = result
                        
                        # æå–è¾“å‡º
                        output = ""
                        if isinstance(result, dict) and "messages" in result:
                            for msg in reversed(result["messages"]):
                                if isinstance(msg, AIMessage):
                                    output = msg.content
                                    break
                        elif isinstance(result, dict) and "output" in result:
                            output = result["output"]
                        elif isinstance(result, list):
                            for msg in reversed(result):
                                if isinstance(msg, AIMessage):
                                    output = msg.content
                                    break
                        
                        logger.info(f"Agent execution completed, output: {output[:100] if output else 'empty'}...")
                        agent_done = True
                    except Exception as e:
                        logger.error(f"Error in stream chat: {e}")
                        import traceback
                        logger.error(traceback.format_exc())
                        agent_error = str(e)
                        agent_done = True
                
                # å¯åŠ¨agentä»»åŠ¡
                agent_task = asyncio.create_task(run_agent())
                
                # æµå¼è¿”å›å›è°ƒå¤„ç†å™¨çš„æ•°æ®
                last_activity = asyncio.get_event_loop().time()
                empty_loops = 0
                
                while not agent_done or stream_handler.has_new_data():
                    # æ£€æŸ¥å›è°ƒå¤„ç†å™¨çš„æ•°æ®ï¼ˆåŒ…å«tokençº§åˆ«çš„æµå¼è¾“å‡ºï¼‰
                    if stream_handler.has_new_data():
                        chunk = stream_handler.get_latest_chunk()
                        if chunk:
                            yield chunk
                            last_activity = asyncio.get_event_loop().time()
                            empty_loops = 0
                        else:
                            empty_loops += 1
                    else:
                        empty_loops += 1
                    
                    # å¦‚æœè¿ç»­å¤šæ¬¡æ²¡æœ‰æ•°æ®ï¼Œç¨å¾®å»¶é•¿ç­‰å¾…æ—¶é—´
                    if empty_loops > 10:
                        await asyncio.sleep(0.2)
                        empty_loops = 0
                    else:
                        await asyncio.sleep(0.05)
                    
                    # æ£€æŸ¥è¶…æ—¶ï¼ˆ120ç§’æ— æ´»åŠ¨ï¼‰
                    current_time = asyncio.get_event_loop().time()
                    if current_time - last_activity > 120 and not agent_done:
                        logger.warning("Stream timeout, agent may be stuck")
                        break
                
                # ç­‰å¾…agentä»»åŠ¡å®Œæˆ
                try:
                    await asyncio.wait_for(agent_task, timeout=5.0)
                except asyncio.TimeoutError:
                    logger.warning("Agent task wait timeout")
                except Exception as e:
                    logger.error(f"Agent task error: {e}")
                
                # å‘é€å‰©ä½™å†…å®¹
                while stream_handler.has_new_data():
                    chunk = stream_handler.get_latest_chunk()
                    if chunk:
                        yield chunk
                
                # å¦‚æœæœ€ç»ˆç»“æœè¿˜æ²¡æœ‰é€šè¿‡æµå¼å‘é€ï¼Œå‘é€æœ€ç»ˆè¾“å‡º
                if final_result:
                    output = ""
                    if isinstance(final_result, dict) and "messages" in final_result:
                        for msg in reversed(final_result["messages"]):
                            if isinstance(msg, AIMessage):
                                output = msg.content
                                break
                    elif isinstance(final_result, dict) and "output" in final_result:
                        output = final_result.get('output', '')
                    elif isinstance(final_result, list):
                        for msg in reversed(final_result):
                            if isinstance(msg, AIMessage):
                                output = msg.content
                                break
                    
                    if output:
                        # æ£€æŸ¥æ˜¯å¦å·²ç»é€šè¿‡æµå¼å‘é€äº†
                        if not stream_handler.in_final_answer or len(output) > len(stream_handler.current_thinking):
                            # å¦‚æœè¾“å‡ºè¿˜æ²¡æœ‰å®Œå…¨å‘é€ï¼Œå‘é€å‰©ä½™éƒ¨åˆ†
                            if "Final Answer:" in output or len(output) > 50:
                                # æå–æœ€ç»ˆç­”æ¡ˆéƒ¨åˆ†
                                if "Final Answer:" in output:
                                    parts = output.split("Final Answer:", 1)
                                    if len(parts) > 1:
                                        final_content = parts[1].strip()
                                        if final_content:
                                            # é€å­—ç¬¦å‘é€ä»¥æ¨¡æ‹Ÿæµå¼æ•ˆæœ
                                            for char in final_content:
                                                yield {
                                                    "type": "content",
                                                    "data": {"content": char},
                                                    "timestamp": datetime.now().isoformat()
                                                }
                                else:
                                    # ç›´æ¥å‘é€è¾“å‡º
                                    for char in output:
                                        yield {
                                            "type": "content",
                                            "data": {"content": char},
                                            "timestamp": datetime.now().isoformat()
                                        }
                
                # æ£€æŸ¥é”™è¯¯
                if agent_error:
                    yield {"type": "error", "data": {"message": agent_error}, "timestamp": datetime.now().isoformat()}
                else:
                    yield {"type": "done", "data": {}, "timestamp": datetime.now().isoformat()}
                    
            except Exception as e:
                logger.error(f"Error in stream processing: {e}")
                import traceback
                logger.error(traceback.format_exc())
                yield {"type": "error", "data": {"message": str(e)}, "timestamp": datetime.now().isoformat()}
                    
        except Exception as e:
            logger.error(f"Error in chat_stream: {e}")
            yield {"type": "error", "data": {"message": str(e)}, "timestamp": datetime.now().isoformat()}
    async def plan_task(
        self, 
        task_description: str,
        config: Optional[AgentConfig] = None,
        **kwargs  # ä¿æŒå‘åå…¼å®¹ï¼Œæ”¯æŒæ—§çš„æ–¹å¼ä¼ å‚
    ) -> Dict:
        """ä»»åŠ¡è§„åˆ’
        
        Args:
            task_description: ä»»åŠ¡æè¿°
            config: Agenté…ç½®å¯¹è±¡ï¼ˆæ¨èä½¿ç”¨ï¼‰
            **kwargs: å‘åå…¼å®¹çš„æ—§å‚æ•°æ–¹å¼ï¼ˆå¦‚æœæä¾›äº†configï¼Œkwargså°†è¢«å¿½ç•¥ï¼‰
                - provider: LLMæä¾›å•†
                - model: æ¨¡å‹åç§°
        """
        # å¦‚æœæä¾›äº†kwargsä½†æ²¡æœ‰configï¼Œä»kwargsåˆ›å»ºconfigï¼ˆå‘åå…¼å®¹ï¼‰
        if config is None and kwargs:
            config = AgentConfig(**kwargs)
        elif config is None:
            config = AgentConfig()
        
        try:
            agent_config = AgentConfig(
                provider=config.provider,
                model=config.model
            )
            agent = await self.create_async_agent(config=agent_config)
            
            prompt = f"è¯·ä¸ºä»¥ä¸‹ä»»åŠ¡åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ï¼š{task_description}"
            messages = [HumanMessage(content=prompt)]
            response = await agent.ainvoke({"messages": messages})
            
            # æå–è¾“å‡º
            output = ""
            if isinstance(response, dict) and "messages" in response:
                for msg in reversed(response["messages"]):
                    if isinstance(msg, AIMessage):
                        output = msg.content
                        break
            elif isinstance(response, dict) and "output" in response:
                output = response["output"]
            elif isinstance(response, list):
                for msg in reversed(response):
                    if isinstance(msg, AIMessage):
                        output = msg.content
                        break
            
            return {
                "success": True,
                "plan": output,
                "steps": self._parse_plan(output)
            }
            
        except Exception as e:
            logger.error(f"Error in plan_task: {e}")
            return {
                "success": False,
                "plan": "",
                "steps": []
            }
    
    def _parse_plan(self, plan_text: str) -> List[Dict]:
        """è§£æè®¡åˆ’æ–‡æœ¬ä¸ºç»“æ„åŒ–æ­¥éª¤"""
        steps = []
        lines = plan_text.split('\n')
        
        for line in lines:
            line = line.strip()
            if line and (line[0].isdigit() or line.startswith('-')):
                # æå–æ­¥éª¤
                step_text = line.lstrip('0123456789.-) ').strip()
                if step_text:
                    steps.append({
                        "description": step_text,
                        "status": "pending"
                    })
        
        return steps


# å…¨å±€å®ä¾‹
agent_service = AgentService()

